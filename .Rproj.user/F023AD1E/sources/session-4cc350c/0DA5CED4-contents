---
title             : "A case for case studies in L3 research: a simulation study of VOT production"
shorttitle        : "L3 VOT Simulation"

author: 
  - name          : "Kyle Parrish"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "15 Seminary Place, New Brunswick, NJ"
    email         : "kyle.parrish@rutgers.edu"


affiliation:
  - id            : "1"
    institution   : "Rutgers University"

abstract: |

 The present study was an approximate replication of Rothman (2011) and examined the determiner phrase (DP) syntax of a large sample (n = 211) of L3 learners of Portuguese who spoke English and Spanish. 
 Rothman (2011) investigated whether L3 Italian or Brazilian Portuguese speakers would be differently impacted by another known Romance Language if it was their L1 or L2.
 The original study concluded that groups did not perform differently on the experimental tasks on the basis of a null effect, and that the typological similarity of Spanish and Portuguese or Italian, relative to English, predicts transfer in the initial stages of L3 acquisition. 
 The present replication recreated all materials, which were not available, but examined the same population and questions.
 Rather than examining L3 Italian and L3 Brazilian Portuguese, the present work maintained a constant L3, Portuguese 
 The learners were divided into two groups in a mirror-image design (n = 96 L1 English-L2 Spanish, n = 115 L1 Spanish-L2 English) and data was collected completely online.
 Like the original study, there was not a main effect of group in any of the two-way Analyses of Variance.
 However, these results show that it should not be assumed that experimental groups behave equivalently based on a null effect: out of four total post-hoc tests of equivalence, only two were significant when the equivalence bounds were set at a small effect size (d = +/- .4). 
 Ultimately, it is argued that determining the smallest effect size of interest and subsequent equivalence testing are necessary to answer key questions in the field of L3 acquisition.
 

  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "L3 acquisition, simulation, voice onset time, L3 phonetics and phonology"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
csl: "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---
```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```



# Introduction

In the last few decades, there has been increasing discussion surrounding third language acquisition, in which a range of studies have been carried out across linguistic domains, including (morpho)syntax and phonetics and phonology. Originally proposed in morphosyntax, one key debate in the field surrounds whether the L3 is influenced in a wholesale fashion by either an L1 or L2 (citations), or whether both of these known languages can simultaneously influence the L3. One view of simultaneous influence of both source languages on the L3 is postulated in the Linguistic Proximity Model (citation). In this view it is predicted that a measured L3 value from an experiment will fall between L1 and L2 values, and, presumably, that the L3 pass inferential statistical tests (be "significantly different"). For example, Westergaard et al. found that the percentage of correct grammaticallity judgments of group X fell between the judgments of group A and group B, suggesting influence of X and Y on their L3 judgments. Although this model was originally proposed for morphosyntax, there is also evidence of intermediate production in L3 phonetics in phonology in VOT (citations). Overall, these findings constitute evidence for the LPM and suggest that its predictions could be extended to phonetics and phonology.

It is important to note, however, that other studies have concluded that whole language influence occurs, both in morphosyntax (cite) and phonetics and phonology (cite). This argument has been made primarily on the basis of null effects of inferential statistical tests. There are at least two potential problems with this manner of evaluation of results. The first concerns statistical power. Given the low sample sizes (that are likely necessary) in L3 research, the power to detect a true underlying effect might not be sufficient. In other words, as our effect of interest gets smaller and variation increases, larger samples are needed to detect that effect. If a sample is not sufficiently large, then it will, with increasing probability, fail to detect a difference that actually exists (a false negative finding). The second, problem, closely related to the first, concerns the lack of a specified meaningful effect for one view or the other. That is, how much of a difference (significant or not) corresponds to clear evidence of simultaneous language influence, and under which threshold are differences not considered meaningful in practice and taken as evidence for wholesale transfer?

One possible tool that can help contribute to this debate is power analysis. Power analysis, proposed by Cohen (cite), is primarily carried out to determine the probability of detecting an effect when it exists. Power also directly tells the researcher the probability of a false negative finding by way of subtraction from 1 (e.g., a study with .8 power has a .2 probability of being a false negative finding). In a simplified version of a power analysis (for example, not using mixed models), the researcher must specify three of four variables: sample size n (referring to participants per group, usually), alpha (the significance threshold; typically .05), a desired power level (typically .8) and an effect size (e.g. Cohen's D). The effect size measure of Cohen's D compares a quantity of pooled standard deviations between conditions, and thus takes into account both the size of the effect and the variation simultaneously. For example, a mean difference of 10 when the pooled standard deviation is 20 is d = .5, and a mean difference of 20 when the pooled standard deviation is 40 is also d = .5. One weakness of this approach, though, is that it typically does not account well for repeated measures designs, where there are sources of variation from both participants and items (stimuli). In this case, power analysis becomes more challenging, since the researcher now must specify how much variation the would expect from participants and items individually, in addition to a given effect size (in raw units/mean difference). Many power analyses are carried out by simulation in R using a variety of packages, such as simr (name more).

The present work is a simulation of L3 voice onset time (VOT) that systematically manipulates the number of stimuli, participants, and their variation to examine their impact on power in the context of L3 acquisition. It simulated an L1 English speaker who has learned L2 Spanish is now learning an L3 which is simulated to fall directly between their L1 and L2. The key question is at what level of variation in the stimuli and participants is this underlying group effect too difficult to detect.

This work aims to make specific recommendations for how many participants and stimuli are needed when certain levels of variation are present relative to a given effect.

Power to detect two effects at once, rather than just one.

This is not applied to mixed effects modeling: how does variation in items, number of items, number of participants, and variation in their L2 and L3 impact power to detect both effects?

The present study is a simulation, using VOT as an example. The primary purpose of this simulation is to make specific recommendations for achieving statistical power in L3 research (simultaneously finding both L3-L1 and L3-L2 differences when they exist). The simulation systematically manipulates variation in participants and items and investigates their interaction with number of participants and number of stimuli.

The present work also addresses a more general question as a byproduct of this analysis: how many items per condition are necessary in addition to number of participants? It is important for many research

RQ: What is a good general recommendation for both a number of participants and number of stimuli in L3 research?

## Effect Sizes and simulations 

Cohen's D is used in a lot of simulations and labeled as small, medium or large. The present work avoids this when possible, but rather contextualizes the effect size (mean difference) in proportion to the variance estimated for participants and items.

Many simulations find that small effects (d = .1) need many observations to detect. This is true, but it is not necessarily due to the size of the effect itself, but rather the size of the effect in the context of the variation of the data. In raw units, d = .1 would correspond to a mean difference of 10 when the pooled standard deviation is 100. The same mean difference would be called a large difference if the standard deviation were much smaller (sd = 10). In fact, if we consider L2 effect sizes (Plonsky) of .4, .7 and 1, a mean difference of 10 could be small if the pooled standard deviation is 25, medium when it is 14.29, and large when it is 10.

## VOT in L1, L2 and L3

Voice onset time (VOT; cite) is an acoustic correlate of stop consonants. It refers to the difference between the release (?) and the onset of laryngeal voicing and is measured in milliseconds. VOT has been a widely studied acoustic measure to investigate a wide array of topics in phonetics and phonology, including cross-linguistic influence.

Languages generally fall into a few distinct classes regarding VOT: true voicing languages and long lag-short lag languages. True voicing languages typically realize phonemically voice stop consonants (/b/, /d/, /g/) as phonetically voiced, in which the VOT is negative, while voiceless consonants (/p/, /t/, /k/) are also voiceless both phonemically and phonetically, and VOT is positive. On the other hand, stops in long lag - short lag languages are all phonetically voiceless, despite /b/, /d/. and /g/, being categorized a "voiced" phonemes. As a result, long lag - short lag languages' stop consonants all have a positive VOT, but the "voiced" variants have a short lag VOT (around 15ms or so) and the voiceless variants are long lag VOT (a positive value around 60ms or so). English and Spanish are a good examples, in which English is a long lag - short lag language (like many Germanic languages) and Spanish is a true voicing language (like many Romance languages).

Research in VOT has look a lot at participants whose L1 is one class of language and the L2 is another, and found a great deal of variability in L2 VOT relative to L1 VOT. Flege and colleagues have published a large body of work in L2 phoentics and phonology with VOT at the centerfold.

L3 phonetics and phonology has also made frequent use of VOT as a window into cross-linguistic influence, and found variability (relative to L1 VOT). It is surprising that many speakers who already have acquired both a true voicing language and a long lag - short lag language do not necessarily immediately produce the L3 as one or the other, but rather something in between. For example...

For the purpose of this simulation and on the basis of previous literature, it is assumed that L1 VOT will be less variable than L2 and L3 VOT. As a result, L1 VOT will be held constant (sd = 20), while the L2 and L3 will be systematically varied.

## L3 models and their predictions 

might be better for discussion if flow is weird

Lack of an effect still would not be evidence of absence - this study serves as a baseline for detecting effect, rather than equivalence.

## The Present Study 

The present study simulated a situation in which there is an L1 English, L2 Spanish speaker who also speaks a third language. The goal of the simulation was to determine how many participants and how many experimental items are needed to consistently detect both an L1-L3 difference and an L2-L3 difference using a mixed effects linear model. The simulation procedure is explained step by step below, followed by the results. All code used to generate the simulation and this manuscript can be found here: osf link.

<!-- old -->

# Literature Review

## Statistical Power in social sciences and linguistics

Broadly, research in the social sciences and linguistics are interested in making generalizations about a group of people or phenomenon by conducting an experiment on only a small sample. Using this sample, inferential statistics are run and their results are "translated" into prose in support (or not) of a given theory. Several problems inevitably arise during this process. Firstly, it can be a challenge to determine how many participants a study should recruit in order to find a given effect, and how large an effect might be (if there indeed is one at all). Secondly, it can be unclear how many observations (or data points) should be collected from each individual in order to reliably characterize their behavior.

In order to determine one or both of these numbers, a researcher must estimate what the size of the effect that they hope to find for the purpose of a power analysis. A power analysis, first proposed by X is the probability of finding an effect that actually exists. It can be calculated with three variables: a significance threshold (the false postive rate or alpha, typically .05 in social sciences), the number of participants per group (N) and an estimation of the true effect's size, which should contain mean differences and standard deviations. Using these three variables, simulations can be run using a programming language such as R in which, over several iterations, two distributions of data are generated with two means and two standard deviations (derived from the proposed effect size). In each iteration (run of a continuous loop function), a specified number of data are generated (N the number of participants per group) and the two data sets are then compared using an inferential statistical procedure (such as a t-test). The power is the proportion of these tests that returns a positive result (finds a signigicant result) divided by the total number of iterations. So, for example, if 100 iterations are run for an effect and 30 of them are positive, the power of the test would be .3. This number suggests that there is only a 30% chance that the given number of participants per group find what we believe to be a real effect, and that there is a 70% chance of a false negative finding.

<!-- make a plot of 100 distributions at .3 power vs at .7 power --->

This example, however, is an oversimplification in light of more recent choices in statistical analysis. The use of multilevel models uncove some potential problems from simpler models used in some research, such as the Analysis of Variance. At one time, it was common practice to collect repeated measures of a given condition, but to reduce these repititons to a single data point using a central tendancy (such as the mean). These means would then be submitted to the model, rather than individual data points. As a result, it was not always possible to determine the certainty of the estimate being used to characterize an individual's behavior. Multilevel models address this problem using random effect structures. Random effects avoid pseudo-replication, or rtificial increases to the sample size resulting in over-confidence and increases in the probability of a false positive finding, by telling the model that there is a nested sturcture to the data and estimating the variance of its random effect (such as experimental items or participants). By examing the random effect, the researcher can see if any particular participant or item was markedly distinct from the field.

Random effects add a new layer to a power analysis. How many participants are needed, and how many data points per condition are necessary to characterize their behavior reliably? Using simulation, Brysbaert (xxxx) suggested that a small effect size (Cohen's D = .4) would need around 1600 observations per condtion in total (for example, 40 participants with 40 observations each) to be powered at the .8 level.

In an ideal situation where .4 is well justified as the SESOI and the population of interest exists, and the design is simple enough, this can certainly be an ideal recommendation.

-   This comes from an assumption about the levels or variance that will be encountered

## Getting numbers to simulate from the literature

The simulated speakers are intented to be American English L1, Spanish L2 and French L3 speakers. L1 American English has been reported to have a population mean of 50.8ms (sd = 21.1) for /p/ @chodroff2015structured.

## Samples in L3 research

### L3 studies are probably underpowered

### The problem with "groups" in language research

The problem for statistical power in L3 research in particular is the issue of faithful groups. There has been much noted variation: not all individuals belonging to the same "group" demonstrate the same behavior. So then, do two inidviduals who both speak, say English as their L1, Spanish as their L2, and French as their L3 belong in a group together if they behave quite differently?

However, there is sadly not always a wealth or resource, nor are there always theoretical grounds to place multiple individuals in the same "group". L2 and L3 acquisition are ideal examples of this, where many individual differences in learning outcomes and sensitivity to different factors may impact some participants differently than others.

## Simulations

<!-- plots -->

# Simulation 1: How many tokens are necessary to reliably distinguish 3 languages in an individual?

The purpose was... Done in R using nested for loops (all scripts available at OSF). 450,000 iterations total (3 effect sizes x 15 sample sizes x 10,000 iterations of each combination) and took 11.36 minutes.

<!-- show the results for only getting a main effect -->

Takeaways: only takes about \<30 observations to get a main effect for small effect size, and 10 or less for medium and large effects, but this is not what we actually want.

<!-- show the results for getting all 3 effects -->

Takeaways: we now need between 130-140 per condition if we believe the effect is small, 50 if its medium and between 20-30 if its large.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
